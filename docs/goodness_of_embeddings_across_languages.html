---

title: Title


keywords: fastai
sidebar: home_sidebar



nb_path: "02_goodness_of_embeddings_across_languages.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 02_goodness_of_embeddings_across_languages.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="How-do-you-evaluate-goodness-of-embeddings-across-languages?">How do you evaluate goodness of embeddings across languages?<a class="anchor-link" href="#How-do-you-evaluate-goodness-of-embeddings-across-languages?"> </a></h2><p>If you have embeddings for language A and another set of embeddings for language B, how can you tell how good they are?</p>
<p>We might want to evaluate each set on a task specific to that language. But a much more interesting proposition is aligning the embeddings in an unsupervised way and evaluating the performance on translation!</p>
<p>For this, we need 3 components. <a href="https://fasttext.cc/docs/en/pretrained-vectors.html">The embeddings</a>, <a href="https://github.com/artetxem/vecmap">a way to align embeddings</a> and <a href="https://github.com/facebookresearch/MUSE">dictionaries</a> we can use to evaluate the results.</p>
<p>Let's begin by grabbing embeddings for English and Polish.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>wget -P data https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.vec
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>--2020-09-14 17:58:30--  https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.vec
Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...
Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 6597238061 (6.1G) [binary/octet-stream]
Saving to: ‘data/wiki.en.vec’

wiki.en.vec         100%[===================&gt;]   6.14G  55.4MB/s    in 1m 56s  

2020-09-14 18:00:26 (54.5 MB/s) - ‘data/wiki.en.vec’ saved [6597238061/6597238061]

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>wget -P data https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.pl.vec
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>--2020-09-14 18:00:26--  https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.pl.vec
Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...
Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 2707436342 (2.5G) [binary/octet-stream]
Saving to: ‘data/wiki.pl.vec’

wiki.pl.vec         100%[===================&gt;]   2.52G  31.6MB/s    in 71s     

2020-09-14 18:01:37 (36.6 MB/s) - ‘data/wiki.pl.vec’ saved [2707436342/2707436342]

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Time to align the embeddings. Let's translate from Polish to English. In order to do that, let's align our Polish embeddings with our English embeddings.</p>
<p>Bear in mind that this is a challenging task - Polish and English come from distinct and very different language families (West Slavic languages of the Lechitic group and West Germanic language of the Indo-European language family respectively).</p>
<p>Let us clone <a href="https://github.com/artetxem/vecmap">vecmap</a> to a directory adjacent to this one and perform the alignment.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>
<span class="err">!</span><span class="n">python</span> <span class="o">../</span><span class="n">vecmap</span><span class="o">/</span><span class="n">map_embeddings</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">cuda</span> <span class="o">--</span><span class="n">unsupervised</span> <span class="n">data</span><span class="o">/</span><span class="n">wiki</span><span class="o">.</span><span class="n">pl</span><span class="o">.</span><span class="n">vec</span> <span class="n">data</span><span class="o">/</span><span class="n">wiki</span><span class="o">.</span><span class="n">en</span><span class="o">.</span><span class="n">vec</span> <span class="n">data</span><span class="o">/</span><span class="n">wiki</span><span class="o">.</span><span class="n">pl</span><span class="o">.</span><span class="n">aligned</span><span class="o">.</span><span class="n">vec</span> <span class="n">data</span><span class="o">/</span><span class="n">wiki</span><span class="o">.</span><span class="n">en</span><span class="o">.</span><span class="n">aligned</span><span class="o">.</span><span class="n">vec</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 17.8 s, sys: 5.69 s, total: 23.5 s
Wall time: 26min 45s
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Great! We now have the English and Polish embeddings aligned to live in the same embedding space!</p>
<p>Let's grab a Polish to English dictionary from the MUSE repository.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>wget -P data https://dl.fbaipublicfiles.com/arrival/dictionaries/pl-en.txt
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>--2020-09-14 18:28:23--  https://dl.fbaipublicfiles.com/arrival/dictionaries/pl-en.txt
Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 172.67.9.4, ...
Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1216386 (1.2M) [text/plain]
Saving to: ‘data/pl-en.txt’

pl-en.txt           100%[===================&gt;]   1.16M  --.-KB/s    in 0.03s   

2020-09-14 18:28:24 (34.8 MB/s) - ‘data/pl-en.txt’ saved [1216386/1216386]

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This dictionary is just a text file with a source and target word per line</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>head data/pl-en.txt
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>roku	year
jest	is
nie	not
przez	through
przez	by
jako	as
oraz	and
był	was
jego	his
jego	its
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's wrap it in a Python class to make usage of it easier.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Dictionary" class="doc_header"><code>class</code> <code>Dictionary</code><a href="https://github.com/fastai/embedding_gym/tree/master/embedding_gym/core.py#L110" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Dictionary</code>(<strong><code>path_to_dict</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pl_en_dict</span> <span class="o">=</span> <span class="n">Dictionary</span><span class="p">(</span><span class="s1">&#39;data/pl-en.txt&#39;</span><span class="p">)</span>
<span class="n">pl_en_dict</span><span class="p">[</span><span class="s1">&#39;królowa&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;queen&#39;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">pl_en_dict</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>73901</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Thanks to <a href="https://github.com/fastai/nbdev">nbdev</a>, we can conveniently import the Embeddings class we defined in the earlier notebook and use it here.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">embedding_gym.core</span> <span class="kn">import</span> <span class="n">Embeddings</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's limit ourselves to the most common 50 000 words from each set of embeddings.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>

<span class="n">embeddings_pl</span> <span class="o">=</span> <span class="n">Embeddings</span><span class="o">.</span><span class="n">from_txt_file</span><span class="p">(</span><span class="s1">&#39;data/wiki.pl.aligned.vec&#39;</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">50_000</span><span class="p">)</span>
<span class="n">embeddings_en</span> <span class="o">=</span> <span class="n">Embeddings</span><span class="o">.</span><span class="n">from_txt_file</span><span class="p">(</span><span class="s1">&#39;data/wiki.en.aligned.vec&#39;</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">50_000</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 11.8 s, sys: 368 ms, total: 12.2 s
Wall time: 11.7 s
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's see if our mechanism for translation works!</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">embeddings_en</span><span class="o">.</span><span class="n">nn_words_to</span><span class="p">(</span><span class="n">embeddings_pl</span><span class="p">[</span><span class="s1">&#39;jest&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;is&#39;, &#39;makes&#39;, &#39;are&#39;, &#39;becomes&#39;, &#39;has&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>That it does - 'jest' means 'is' in Polish!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Our translation results will be adversaly affected by synonyms. What we can however do is limit the task to words where the source and the target word exist in source and target embeddings.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>

<span class="n">topk</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">source_embeddings</span> <span class="o">=</span> <span class="n">embeddings_pl</span>
<span class="n">target_embeddings</span> <span class="o">=</span> <span class="n">embeddings_en</span>

<span class="n">correct</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">source_word</span> <span class="ow">in</span> <span class="n">source_embeddings</span><span class="o">.</span><span class="n">i2w</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">source_word</span> <span class="ow">in</span> <span class="n">pl_en_dict</span><span class="o">.</span><span class="n">source_words</span> <span class="ow">and</span> <span class="n">pl_en_dict</span><span class="p">[</span><span class="n">source_word</span><span class="p">]</span> <span class="ow">in</span> <span class="n">target_embeddings</span><span class="o">.</span><span class="n">i2w</span><span class="p">:</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">pl_en_dict</span><span class="p">[</span><span class="n">source_word</span><span class="p">]</span> <span class="ow">in</span> <span class="n">embeddings_en</span><span class="o">.</span><span class="n">nn_words_to</span><span class="p">(</span><span class="n">embeddings_pl</span><span class="p">[</span><span class="n">source_word</span><span class="p">],</span> <span class="n">n</span><span class="o">=</span><span class="n">topk</span><span class="p">):</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 32min 53s, sys: 25.5 s, total: 33min 18s
Wall time: 4min 10s
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">,</span> <span class="n">total</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(0.5911755937593163, 20126)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Nearly 60% accuracy with topk@1 across 20 thousand words! That seems like a great result given that we are not making any accomodations for synonyms. Let's see what results we get with topk@5.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>

<span class="n">topk</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">source_embeddings</span> <span class="o">=</span> <span class="n">embeddings_pl</span>
<span class="n">target_embeddings</span> <span class="o">=</span> <span class="n">embeddings_en</span>

<span class="n">correct</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">source_word</span> <span class="ow">in</span> <span class="n">source_embeddings</span><span class="o">.</span><span class="n">i2w</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">source_word</span> <span class="ow">in</span> <span class="n">pl_en_dict</span><span class="o">.</span><span class="n">source_words</span> <span class="ow">and</span> <span class="n">pl_en_dict</span><span class="p">[</span><span class="n">source_word</span><span class="p">]</span> <span class="ow">in</span> <span class="n">target_embeddings</span><span class="o">.</span><span class="n">i2w</span><span class="p">:</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">pl_en_dict</span><span class="p">[</span><span class="n">source_word</span><span class="p">]</span> <span class="ow">in</span> <span class="n">embeddings_en</span><span class="o">.</span><span class="n">nn_words_to</span><span class="p">(</span><span class="n">embeddings_pl</span><span class="p">[</span><span class="n">source_word</span><span class="p">],</span> <span class="n">n</span><span class="o">=</span><span class="n">topk</span><span class="p">):</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 32min 58s, sys: 26.3 s, total: 33min 24s
Wall time: 4min 10s
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">,</span> <span class="n">total</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(0.7637384477789924, 20126)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

